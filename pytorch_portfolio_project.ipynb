{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Fashion MNIST Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though this notebook covers a well documented dataset with plenty of examples covering it, I hope to demonstrate what I have learned so far about pytorch and its architecture.\n",
    "\n",
    "This notebook only uses pytorch; documentation can be found at https://pytorch.org/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # PyTorch\n",
    "import torch.nn as nn # Neural network module\n",
    "import torch.optim as optim # Optimization module\n",
    "import torch.nn.functional as F # Functional module (activation functions, etc.)\n",
    "from torchvision import datasets, transforms # Datasets and transformations\n",
    "from torch.utils.data import DataLoader # Data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Class for the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model I decied to use a model that incorporates CNN layers as they are commonly included when analyzing photographs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CNN class for the model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        # Call the constructor of the parent class (nn.Module)\n",
    "        super(CNN, self).__init__()\n",
    "        # First convolutional layer: 1 input channel, 32 output channels, 3x3 kernel\n",
    "        # the 3x3 kernel is a common choice for image processing tasks\n",
    "        # It is small enough to capture local patterns, but large enough to capture complex patterns\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        # Batch normalization for the first convolutional layer\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        # Second convolutional layer: 32 input channels, 64 output channels, 3x3 kernel\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        # Batch normalization for the second convolutional layer\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        # Third convolutional layer: 64 input channels, 128 output channels, 3x3 kernel\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        # Batch normalization for the third convolutional layer\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        # Fully connected layer\n",
    "        # The input size is calculated as follows: 128 channels, 11x11 spatial dimensions\n",
    "        # The spatial dimensions are calculated as follows: (original_size - kernel_size + 2*padding) / stride + 1\n",
    "        # Padding is 0 by default, stride is 1 by default\n",
    "        self.fc1 = nn.Linear(128 * 11 * 11, 256)\n",
    "        # Dropout layer with a dropout probability of 0.5\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        # Fully connected layer: input size 256, output size 128\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        # Fully connected layer: input size 128, output size 10 (number of classes)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply first convolutional layer, followed by batch normalization and ReLU activation\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        # Apply second convolutional layer, followed by batch normalization and ReLU activation\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        # Apply third convolutional layer, followed by batch normalization and leaky_ReLU activation\n",
    "        # Leaky ReLU is similar to ReLU, but allows a small gradient when the input is negative\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)))\n",
    "        # Apply max pooling with a 2x2 kernel\n",
    "        # This reduces the size of the tensor by half in both dimensions (width and height)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # Flatten the tensor into a vector\n",
    "        x = x.view(-1, 128 * 11 * 11)\n",
    "        # Apply first fully connected layer followed by ReLU activation\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Apply dropout layer\n",
    "        x = self.dropout(x)\n",
    "        # Apply second fully connected layer followed by Leaky_ReLU activation\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        # Apply third fully connected layer and return the result (no activation function)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data loaders with data augmentation\n",
    "# The compose function allows us to chain multiple transformations together\n",
    "transform = transforms.Compose([\n",
    "    # The random horizontal flip transformation flips the image horizontally with a 50% probability\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # The random rotation transformation rotates the image by a random angle between -10 and 10 degrees\n",
    "    transforms.RandomRotation(10),\n",
    "    # The to tensor transformation converts the image to a PyTorch tensor\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the FashionMNIST dataset\n",
    "train_data = datasets.FashionMNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.FashionMNIST(root='data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Create data loaders for the training and test datasets\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Training and Testing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = CNN()\n",
    "\n",
    "# Set the criterion equal to the cross-entropy loss function\n",
    "# This function combines the softmax activation function and the negative log-likelihood loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set the optimizer equal to Adam with weight decay\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# Set the learning rate scheduler to decrease the learning rate by a factor of 0.1 every 5 epochs\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training function\n",
    "# The function takes the model, data loader, criterion, optimizer, and number of epochs as input\n",
    "def train(model, train_loader, criterion, optimizer, epochs=5):\n",
    "    # Set model to training mode\n",
    "    model.train()  \n",
    "\n",
    "    # Loop over the number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        # Set the running loss to 0 at the beginning of each epoch\n",
    "        running_loss = 0\n",
    "\n",
    "        # Loop over the data loader\n",
    "        for images, labels in train_loader:\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            # The backward function computes the gradient of the loss with respect to the model parameters\n",
    "            loss.backward()\n",
    "\n",
    "            # The step function updates the model parameters based on the computed gradients\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Add the loss for the current batch to the running loss\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        # Print the average loss for the epoch\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the testing function\n",
    "def test(model, test_loader):\n",
    "    # Set model to evaluation mode\n",
    "    # This is necessary because some layers, such as dropout and batch normalization, behave differently during training and testing\n",
    "    # In testing mode, dropout is disabled and batch normalization uses the running statistics\n",
    "    # The running statistics are updated during training and used during testing\n",
    "    model.eval()  \n",
    "\n",
    "    # Initialize the number of correct predictions and the total number of predictions to 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Disable gradient calculation during testing\n",
    "    with torch.no_grad():  \n",
    "        # Loop over the test data loader\n",
    "        for images, labels in test_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            # Get the class with the highest score\n",
    "            # The _ indicates that we are not interested in the values of the scores, only the indices\n",
    "            _, predicted = torch.max(outputs.data, 1)  \n",
    "            # Update the total number of predictions\n",
    "            total += labels.size(0)\n",
    "            # Update the number of correct predictions\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    # Print the accuracy\n",
    "    print(f'Accuracy: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.6259899374041984\n",
      "Epoch 2/5, Loss: 0.42411979856585136\n",
      "Epoch 3/5, Loss: 0.3714698015023142\n",
      "Epoch 4/5, Loss: 0.3326240563983602\n",
      "Epoch 5/5, Loss: 0.31046547002788544\n",
      "Accuracy: 90.65%\n"
     ]
    }
   ],
   "source": [
    "# Train the model and test it\n",
    "train(model, train_loader, criterion, optimizer, epochs=5)\n",
    "test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model for Use in Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things I would do to improve the model is add epochs to take advantage of a lower learning rates, add more layers to the network or normalize the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
